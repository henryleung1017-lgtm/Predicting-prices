# Review of `multi_model_ensemble_20y_with_metrics.py`

## What the script does
- Loads 20-year forecasts generated by three base models (LSTM, SARIMAX, GRU) for both daily and monthly frequencies.
- Loads corresponding performance metrics, normalizes columns, and builds RMSE-based weights per ticker/frequency (weights ∝ 1/RMSE²).
- Creates ensemble forecasts per ticker/date via weighted averages; falls back to equal weights if no RMSE weights are available.
- Approximates ensemble uncertainty with a weighted RMSE formula to build 95% confidence intervals.
- Produces an ensemble performance summary that includes base models plus an ensemble row (approximated MAE/RMSE).
- Saves ensemble forecasts and summary CSVs to the `forecasts/` directory and shows bar charts of RMSE as well as plots comparing historical Yahoo Finance prices to ensemble forecasts.

## Strengths
- Clear separation between forecast loaders, metric loaders, weight construction, ensemble computation, and visualization.
- Uses standardized column names across disparate metric files, simplifying downstream aggregation.
- Provides a reasonable fallback (equal weights) when metrics are missing, preventing the pipeline from failing outright.
- Approximates ensemble confidence intervals instead of omitting uncertainty entirely, giving users some sense of variability.

## Key issues, risks, and current mitigation status
- **Missing data handling (mitigated)**: The script validates the presence of all required forecast/metric files before running and now enforces column-level schema and numeric checks to catch drift or corrupt values early.
- **Confidence interval assumptions (partially mitigated)**: Confidence intervals can now assume a user-configurable pairwise error correlation (default 0.5) to widen bands when errors are likely correlated. Actual residual correlations are still unknown.
- **Metric consistency (partially mitigated)**: Directional metrics are aggregated for the ensemble when available, and coverage per row is exposed so missing directional metrics are visible. LSTM directional metrics remain `NaN` when not produced upstream.
- **Weight robustness (mitigated)**: Weight calculation keeps the prior warnings for missing RMSEs and now validates metric numeric values, checks for stale metrics when date columns exist, and warns when forecasts lack accompanying metrics.
- **Data leakage / download cost (partially mitigated)**: Plotting can optionally bound history downloads by start date and cache Yahoo Finance responses locally to avoid repeated full-history downloads. Alignment with training spans is still not enforced.
- **Testing and automation (partially mitigated)**: CLI flags now gate plotting, network access, CI correlation assumptions, history download bounds/cache, and metric recency warnings, but formal unit tests are still absent.
- **Performance (partially mitigated)**: Caching downloaded histories reduces repeat network calls, but groupby operations and plotting remain single-threaded.

## Suggested next steps
- Add column-level validation (required headers, dtypes) alongside file existence checks to catch schema drift early.
- Introduce CLI flags or configuration to disable plotting, skip Yahoo downloads, select frequencies, and control output paths for automated workflows.
- Cache or pre-download historical price data and align it to the same adjustment convention as training to avoid leakage and speed up plotting.
- Compute or approximate ensemble directional metrics instead of leaving them `NaN`, or clearly surface their absence in reports.
- Add lightweight tests for weighting, aggregation, and validation logic, and refactor plotting into optional, importable functions to ease automation.
- Profile large runs and consider batching or multiprocessing for forecast aggregation and history fetching.
