# Review of `multi_model_ensemble_20y_with_metrics.py`

## What the script does
- Loads 20-year forecasts generated by three base models (LSTM, SARIMAX, GRU) for both daily and monthly frequencies.
- Loads corresponding performance metrics, normalizes columns, and builds RMSE-based weights per ticker/frequency (weights ∝ 1/RMSE²).
- Creates ensemble forecasts per ticker/date via weighted averages; falls back to equal weights if no RMSE weights are available.
- Approximates ensemble uncertainty with a weighted RMSE formula to build 95% confidence intervals.
- Produces an ensemble performance summary that includes base models plus an ensemble row (approximated MAE/RMSE).
- Saves ensemble forecasts and summary CSVs to the `forecasts/` directory and shows bar charts of RMSE as well as plots comparing historical Yahoo Finance prices to ensemble forecasts.

## Strengths
- Clear separation between forecast loaders, metric loaders, weight construction, ensemble computation, and visualization.
- Uses standardized column names across disparate metric files, simplifying downstream aggregation.
- Provides a reasonable fallback (equal weights) when metrics are missing, preventing the pipeline from failing outright.
- Approximates ensemble confidence intervals instead of omitting uncertainty entirely, giving users some sense of variability.

## Key issues, risks, and current mitigation status
- **Missing data handling (mitigated)**: The script validates the presence of all required forecast/metric files before running, enforces column-level schema and numeric checks, and warns when forecasts lack supporting metrics or when metric values are stale or non-positive.
- **Confidence interval assumptions (partially mitigated)**: Confidence intervals can assume a user-configurable pairwise error correlation (default 0.5) to widen bands when errors are likely correlated. Actual residual correlations remain unknown, so intervals may still be optimistic.
- **Metric consistency (partially mitigated)**: Directional metrics are aggregated for the ensemble when available, and coverage per row is exposed so missing directional metrics are visible. LSTM directional metrics remain `NaN` when not produced upstream.
- **Weight robustness (partially mitigated)**: Weight calculation validates numeric metrics, warns for stale metrics and missing RMSEs, and avoids crashes when forecasts lack accompanying metrics. Recency/coverage checks on the training spans of metrics are still shallow.
- **Data leakage / download cost (partially mitigated)**: Plotting can bound history downloads by start date and cache Yahoo Finance responses to avoid repeated full-history downloads. Alignment with training spans, adjustment conventions, and leakage guards are still not enforced.
- **Testing and automation (partially mitigated)**: CLI flags gate plotting, network access, CI correlation assumptions, history download bounds/cache, metric recency warnings, and forecast validation, but formal unit tests and CI automation are still absent.
- **Performance (partially mitigated)**: Caching downloaded histories reduces repeat network calls, but groupby operations, validation, and plotting remain single-threaded with no batching for large ticker sets.

## Suggested next steps
- Empirically estimate residual correlations between models and calibrate confidence intervals through backtests instead of relying solely on the configurable default.
- Derive directional metrics for LSTM forecasts (or downstream) so ensemble directional coverage is complete, or explicitly mark unsupported tickers/frequencies.
- Tighten leakage controls by aligning historical downloads to the training spans/adjustment conventions and enforcing explicit validation of lookback windows.
- Add lightweight unit tests for validation, weighting, recency checks, and CI construction, and wire them into CI along with non-plotting CLI smoke tests.
- Profile and batch groupby-heavy steps and Yahoo downloads (e.g., multiprocessing or per-frequency caching) to handle larger ticker universes.
